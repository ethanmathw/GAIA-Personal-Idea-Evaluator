{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"f572b6d414f14a20902c1868e525d0c5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_08d676d5d1b343e2a22287db609b9938","IPY_MODEL_95c020edc4b14dfab51601194d033435","IPY_MODEL_28c9d0c278da4279850985e8aaef0585"],"layout":"IPY_MODEL_389af82584e14307915fefb8bcea7998"}},"08d676d5d1b343e2a22287db609b9938":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0459ba080b7a425c9741580850d9d25b","placeholder":"​","style":"IPY_MODEL_a7977029ac784ecfbb46aec25181037c","value":"config.json: 100%"}},"95c020edc4b14dfab51601194d033435":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d389357c18c74a3aab3eecb68654f9b2","max":608,"min":0,"orientation":"horizontal","style":"IPY_MODEL_53fb68852a1147cc80b0c7e0a7326704","value":608}},"28c9d0c278da4279850985e8aaef0585":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ee292481d164c84a9b42964207909db","placeholder":"​","style":"IPY_MODEL_36573762dff34094b3120b8b7415858f","value":" 608/608 [00:00&lt;00:00, 17.8kB/s]"}},"389af82584e14307915fefb8bcea7998":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0459ba080b7a425c9741580850d9d25b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7977029ac784ecfbb46aec25181037c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d389357c18c74a3aab3eecb68654f9b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53fb68852a1147cc80b0c7e0a7326704":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5ee292481d164c84a9b42964207909db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36573762dff34094b3120b8b7415858f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a49a59d42f244b478396b4ab6ccfe3b9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_425ab088f2124f51884a693a53cc2f85","IPY_MODEL_2393199b1a7140669e4248b7f4df0d32","IPY_MODEL_64ebaafcaf57461a950fc0a47b476694"],"layout":"IPY_MODEL_767ec7e83f594d4380d3f8e76bf07a68"}},"425ab088f2124f51884a693a53cc2f85":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e9950ecfdfd4204b295891d4dc3ee84","placeholder":"​","style":"IPY_MODEL_db77a39ef3f54b8f8777b8d10233503a","value":"tokenizer_config.json: 100%"}},"2393199b1a7140669e4248b7f4df0d32":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b99eca2222144b6a1de87886df78b32","max":1289,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b49d2dc68a364d4cb1501f3f21219340","value":1289}},"64ebaafcaf57461a950fc0a47b476694":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c19a9c837cc4e3caf3ebee32a310f45","placeholder":"​","style":"IPY_MODEL_5c5c6b245f084c528b4b4b07e02e55a2","value":" 1.29k/1.29k [00:00&lt;00:00, 33.7kB/s]"}},"767ec7e83f594d4380d3f8e76bf07a68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e9950ecfdfd4204b295891d4dc3ee84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db77a39ef3f54b8f8777b8d10233503a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6b99eca2222144b6a1de87886df78b32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b49d2dc68a364d4cb1501f3f21219340":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4c19a9c837cc4e3caf3ebee32a310f45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c5c6b245f084c528b4b4b07e02e55a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9a06eb204d1e402b83f4c48c0c2056b8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2cfdc609f0b544988a3be7f0d705ace5","IPY_MODEL_871ef5964cbb4a97a11eb5efd54c824e","IPY_MODEL_8fc81b2b91f64b5084ed724b3bddd83f"],"layout":"IPY_MODEL_5a765145f0304d578a857b7c83b878d3"}},"2cfdc609f0b544988a3be7f0d705ace5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_093d2c78071a4167bcfe2bbfb72f9f47","placeholder":"​","style":"IPY_MODEL_f5669708617a4a72b3499e2e1f4e5ffa","value":"tokenizer.model: 100%"}},"871ef5964cbb4a97a11eb5efd54c824e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aeb3679ebfa247d9ad77a0393da8fc60","max":499723,"min":0,"orientation":"horizontal","style":"IPY_MODEL_410d182a6f684d2c9cd3c107a26713c6","value":499723}},"8fc81b2b91f64b5084ed724b3bddd83f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ea21ced33cb4d2fa221aaf5e1cb1ec3","placeholder":"​","style":"IPY_MODEL_c570270c37d344a99a81e6c7c5611124","value":" 500k/500k [00:00&lt;00:00, 7.39MB/s]"}},"5a765145f0304d578a857b7c83b878d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"093d2c78071a4167bcfe2bbfb72f9f47":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5669708617a4a72b3499e2e1f4e5ffa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aeb3679ebfa247d9ad77a0393da8fc60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"410d182a6f684d2c9cd3c107a26713c6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0ea21ced33cb4d2fa221aaf5e1cb1ec3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c570270c37d344a99a81e6c7c5611124":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"73028621c71a4df9b6f8715a77a7cd79":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_adf88d12d3bf405d8184a90331915ac7","IPY_MODEL_d8b9063edead43f993b55ed8875d36fd","IPY_MODEL_a97b0bab36984798a2cda55bfb006d6d"],"layout":"IPY_MODEL_ad890110ecb941c3a4ddf3bf8c160e18"}},"adf88d12d3bf405d8184a90331915ac7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_70e0bf6f57f4419e8e447fc8f8ce0eff","placeholder":"​","style":"IPY_MODEL_07cb0d4808534f268866e57f31aca669","value":"tokenizer.json: 100%"}},"d8b9063edead43f993b55ed8875d36fd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f53fc1257ef04deeb011ce1f11c1feb6","max":1842767,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e5cb0a1f1f24453d85b77d546333a9e7","value":1842767}},"a97b0bab36984798a2cda55bfb006d6d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_438868601dc04a43a7361d972d6a59d8","placeholder":"​","style":"IPY_MODEL_a9c734cca4fc4929bc6b1eb4cda4ddb4","value":" 1.84M/1.84M [00:00&lt;00:00, 6.81MB/s]"}},"ad890110ecb941c3a4ddf3bf8c160e18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70e0bf6f57f4419e8e447fc8f8ce0eff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07cb0d4808534f268866e57f31aca669":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f53fc1257ef04deeb011ce1f11c1feb6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5cb0a1f1f24453d85b77d546333a9e7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"438868601dc04a43a7361d972d6a59d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9c734cca4fc4929bc6b1eb4cda4ddb4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6e129b69eb3f4097a1bee58ea7f70929":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_276b1a383f3a4cb68b0f8ebe93003a86","IPY_MODEL_7dbdf44155ca4aed8e44994b6757423b","IPY_MODEL_da0d4f2ffd3e4583b1cdacebc82b0572"],"layout":"IPY_MODEL_2e2e7ed254f549738332263f14d1d5ed"}},"276b1a383f3a4cb68b0f8ebe93003a86":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb08ee57bf60441a8a1cb5e1f6bfd69c","placeholder":"​","style":"IPY_MODEL_0340565d33854bedb50df5433044e156","value":"special_tokens_map.json: 100%"}},"7dbdf44155ca4aed8e44994b6757423b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c38d897e8d414e87a2b53bb55c94d8c8","max":551,"min":0,"orientation":"horizontal","style":"IPY_MODEL_502b3d3016894d3290fb5beadf06491a","value":551}},"da0d4f2ffd3e4583b1cdacebc82b0572":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa81bf63b2a04844b0d9f67eea2e428c","placeholder":"​","style":"IPY_MODEL_bec8508a370545869999dfe22bda6fae","value":" 551/551 [00:00&lt;00:00, 13.9kB/s]"}},"2e2e7ed254f549738332263f14d1d5ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb08ee57bf60441a8a1cb5e1f6bfd69c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0340565d33854bedb50df5433044e156":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c38d897e8d414e87a2b53bb55c94d8c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"502b3d3016894d3290fb5beadf06491a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fa81bf63b2a04844b0d9f67eea2e428c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bec8508a370545869999dfe22bda6fae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9cd38f146aba47d7b3dc177bd6788a74":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8c1b31b3165e433b82861e9e9a0ae705","IPY_MODEL_206abc13e2fd462c9e7310d238bc3796","IPY_MODEL_8a8f81e3965b45d0a4423fce5b7adf53"],"layout":"IPY_MODEL_57a77cb2e66a428787a323bfe6f94f82"}},"8c1b31b3165e433b82861e9e9a0ae705":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8085a41cd1347229829d16225c095f2","placeholder":"​","style":"IPY_MODEL_6dc94c05d9e24005a914ad49c6731112","value":"model.safetensors: 100%"}},"206abc13e2fd462c9e7310d238bc3796":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d5afdd4af3941868e9f6bdc0f9bf7a2","max":2200119864,"min":0,"orientation":"horizontal","style":"IPY_MODEL_11d1577133394519ba0f7539a1b5ac22","value":2200119864}},"8a8f81e3965b45d0a4423fce5b7adf53":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dcfbb4ae468047c0a98ffaebd23172dd","placeholder":"​","style":"IPY_MODEL_cbfd8d5f8f044723997a6dee1ce1fbfa","value":" 2.20G/2.20G [00:22&lt;00:00, 124MB/s]"}},"57a77cb2e66a428787a323bfe6f94f82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8085a41cd1347229829d16225c095f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6dc94c05d9e24005a914ad49c6731112":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7d5afdd4af3941868e9f6bdc0f9bf7a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11d1577133394519ba0f7539a1b5ac22":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dcfbb4ae468047c0a98ffaebd23172dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbfd8d5f8f044723997a6dee1ce1fbfa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"674de677df454f4383a02f64fb9c314a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1827e826bed1467e8676dae3e4249402","IPY_MODEL_7048d8f7d42841a2afce42c7e63ce73c","IPY_MODEL_dbbd81c5e644463fb198f2cd7d7c4ad8"],"layout":"IPY_MODEL_086306edd73d43a9bf15d917f1ed4656"}},"1827e826bed1467e8676dae3e4249402":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3a5382ea38f48af982cd0cd6315a48a","placeholder":"​","style":"IPY_MODEL_86f4e768ad0840348dabba19f23624d4","value":"generation_config.json: 100%"}},"7048d8f7d42841a2afce42c7e63ce73c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e015bcd611c4bf7aeaa7c6a997ae1cd","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f6ad5d99d6384c0aaa66e0b68054f005","value":124}},"dbbd81c5e644463fb198f2cd7d7c4ad8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d13d8df7ef0849ff8f52f32bcc2983ae","placeholder":"​","style":"IPY_MODEL_0737ab821a13421b86305c4651a758fa","value":" 124/124 [00:00&lt;00:00, 6.70kB/s]"}},"086306edd73d43a9bf15d917f1ed4656":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3a5382ea38f48af982cd0cd6315a48a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86f4e768ad0840348dabba19f23624d4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e015bcd611c4bf7aeaa7c6a997ae1cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6ad5d99d6384c0aaa66e0b68054f005":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d13d8df7ef0849ff8f52f32bcc2983ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0737ab821a13421b86305c4651a758fa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"W67znH8kvNjK","colab":{"base_uri":"https://localhost:8080/","height":780,"referenced_widgets":["f572b6d414f14a20902c1868e525d0c5","08d676d5d1b343e2a22287db609b9938","95c020edc4b14dfab51601194d033435","28c9d0c278da4279850985e8aaef0585","389af82584e14307915fefb8bcea7998","0459ba080b7a425c9741580850d9d25b","a7977029ac784ecfbb46aec25181037c","d389357c18c74a3aab3eecb68654f9b2","53fb68852a1147cc80b0c7e0a7326704","5ee292481d164c84a9b42964207909db","36573762dff34094b3120b8b7415858f"]},"executionInfo":{"status":"error","timestamp":1704675070399,"user_tz":300,"elapsed":24977,"user":{"displayName":"Ishaan Salaskar","userId":"15075815353482721876"}},"outputId":"2bcad028-6655-4c30-e0af-99defdf41cc0"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f572b6d414f14a20902c1868e525d0c5"}},"metadata":{}},{"output_type":"error","ename":"ImportError","evalue":"Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-bfd7c46ae974>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text-generation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbfloat16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# We use the tokenizer's chat template to format each message - see https://huggingface.co/docs/transformers/main/en/chat_templating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mframework\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0mmodel_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtargeted_task\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtargeted_task\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m         framework, model = infer_framework_load_model(\n\u001b[0m\u001b[1;32m    871\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0mmodel_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36minfer_framework_load_model\u001b[0;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"eval\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    567\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2672\u001b[0m                 )\n\u001b[1;32m   2673\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_accelerate_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2674\u001b[0;31m                 raise ImportError(\n\u001b[0m\u001b[1;32m   2675\u001b[0m                     \u001b[0;34m\"Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2676\u001b[0m                 )\n","\u001b[0;31mImportError\u001b[0m: Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["# Install transformers from source - only needed for versions <= v4.34\n","\n","import torch\n","from transformers import pipeline\n","\n","pipe = pipeline(\"text-generation\", model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", torch_dtype=torch.bfloat16, device_map=\"auto\")\n","\n","# We use the tokenizer's chat template to format each message - see https://huggingface.co/docs/transformers/main/en/chat_templating"]},{"cell_type":"code","source":["messages = [\n","    {\n","        \"role\": \"system\",\n","        \"content\": \"You are supposed act as an agent that evaluates any problem solution pair on a scale of 1-10 and give feedback. You must return a number grading the solution as well as one sentence feedback on how the solution can be improved\",\n","    },\n","    {\"role\": \"user\", \"content\": '''\n","\n","    Problem: The low-density polyethylene (LPDE) material used to make food packaging and shopping bags makes them unacceptable for recycling more than once.\n","    Solution: \"Low-density polyethylene (LPDE) bags can only be recycled ONCE because they can interfere with sorting machinery.\n","\n","The initiator used in the production of grocery and shopping bags is ORGANIC PEROXIDE, which poses a risk to human health after recycling. Because of all its harmful effects, this initiator is the primary reason for IMPOSSIBLE RECYCLING. When using organic peroxide in any form of product, a REPLACEMENT or RECYCLEABLE INITIATOR should be used.\n","\n","MAKING OF LPDE:\n","\n","Unreacted gas is first compressed by melting natural gas ethylene to form new first-compression gas. In the second compressor, this newly compressed gas is once again melted with unreacted gases. At this point, a catalyst (organic peroxide) and a second compressed gas are mixed into the reactor. Polymerization occurs at a particular pressure and temperature. The unreacted gases are then separated from the polymerization process to extract the polymers, and now they are finally pelletized. Thereafter, the pellets can be dried by injecting hot air. Now, these pellets are used to make plastic bags.\"\n","\n","    '''\n","\n","    },\n","]\n","prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n","outputs = pipe(prompt, max_new_tokens=512, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)\n","print(outputs[0][\"generated_text\"])\n"],"metadata":{"id":"LOfODKKjwaXc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install transformers\n","import transformers\n","from transformers import LlamaForCausalLM, DataCollatorForLanguageModeling\n","from transformers import Trainer, TrainingArguments\n","import torch\n","from transformers import pipeline\n","!pip install accelerate -U\n"],"metadata":{"id":"Kt_cerR4UdUC","executionInfo":{"status":"ok","timestamp":1704675088332,"user_tz":300,"elapsed":12957,"user":{"displayName":"Ishaan Salaskar","userId":"15075815353482721876"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"88159d3b-943f-4952-dd6c-62876743c78f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n","Collecting accelerate\n","  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.1)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Installing collected packages: accelerate\n","Successfully installed accelerate-0.25.0\n"]}]},{"cell_type":"code","source":["model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n","tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n","model = LlamaForCausalLM.from_pretrained(model_name)"],"metadata":{"id":"_zwwyU0Wb9QL","colab":{"base_uri":"https://localhost:8080/","height":209,"referenced_widgets":["a49a59d42f244b478396b4ab6ccfe3b9","425ab088f2124f51884a693a53cc2f85","2393199b1a7140669e4248b7f4df0d32","64ebaafcaf57461a950fc0a47b476694","767ec7e83f594d4380d3f8e76bf07a68","1e9950ecfdfd4204b295891d4dc3ee84","db77a39ef3f54b8f8777b8d10233503a","6b99eca2222144b6a1de87886df78b32","b49d2dc68a364d4cb1501f3f21219340","4c19a9c837cc4e3caf3ebee32a310f45","5c5c6b245f084c528b4b4b07e02e55a2","9a06eb204d1e402b83f4c48c0c2056b8","2cfdc609f0b544988a3be7f0d705ace5","871ef5964cbb4a97a11eb5efd54c824e","8fc81b2b91f64b5084ed724b3bddd83f","5a765145f0304d578a857b7c83b878d3","093d2c78071a4167bcfe2bbfb72f9f47","f5669708617a4a72b3499e2e1f4e5ffa","aeb3679ebfa247d9ad77a0393da8fc60","410d182a6f684d2c9cd3c107a26713c6","0ea21ced33cb4d2fa221aaf5e1cb1ec3","c570270c37d344a99a81e6c7c5611124","73028621c71a4df9b6f8715a77a7cd79","adf88d12d3bf405d8184a90331915ac7","d8b9063edead43f993b55ed8875d36fd","a97b0bab36984798a2cda55bfb006d6d","ad890110ecb941c3a4ddf3bf8c160e18","70e0bf6f57f4419e8e447fc8f8ce0eff","07cb0d4808534f268866e57f31aca669","f53fc1257ef04deeb011ce1f11c1feb6","e5cb0a1f1f24453d85b77d546333a9e7","438868601dc04a43a7361d972d6a59d8","a9c734cca4fc4929bc6b1eb4cda4ddb4","6e129b69eb3f4097a1bee58ea7f70929","276b1a383f3a4cb68b0f8ebe93003a86","7dbdf44155ca4aed8e44994b6757423b","da0d4f2ffd3e4583b1cdacebc82b0572","2e2e7ed254f549738332263f14d1d5ed","cb08ee57bf60441a8a1cb5e1f6bfd69c","0340565d33854bedb50df5433044e156","c38d897e8d414e87a2b53bb55c94d8c8","502b3d3016894d3290fb5beadf06491a","fa81bf63b2a04844b0d9f67eea2e428c","bec8508a370545869999dfe22bda6fae","9cd38f146aba47d7b3dc177bd6788a74","8c1b31b3165e433b82861e9e9a0ae705","206abc13e2fd462c9e7310d238bc3796","8a8f81e3965b45d0a4423fce5b7adf53","57a77cb2e66a428787a323bfe6f94f82","f8085a41cd1347229829d16225c095f2","6dc94c05d9e24005a914ad49c6731112","7d5afdd4af3941868e9f6bdc0f9bf7a2","11d1577133394519ba0f7539a1b5ac22","dcfbb4ae468047c0a98ffaebd23172dd","cbfd8d5f8f044723997a6dee1ce1fbfa","674de677df454f4383a02f64fb9c314a","1827e826bed1467e8676dae3e4249402","7048d8f7d42841a2afce42c7e63ce73c","dbbd81c5e644463fb198f2cd7d7c4ad8","086306edd73d43a9bf15d917f1ed4656","b3a5382ea38f48af982cd0cd6315a48a","86f4e768ad0840348dabba19f23624d4","3e015bcd611c4bf7aeaa7c6a997ae1cd","f6ad5d99d6384c0aaa66e0b68054f005","d13d8df7ef0849ff8f52f32bcc2983ae","0737ab821a13421b86305c4651a758fa"]},"executionInfo":{"status":"ok","timestamp":1704675132705,"user_tz":300,"elapsed":44385,"user":{"displayName":"Ishaan Salaskar","userId":"15075815353482721876"}},"outputId":"08eb0d4b-457b-4beb-8111-d325d442c664"},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a49a59d42f244b478396b4ab6ccfe3b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a06eb204d1e402b83f4c48c0c2056b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73028621c71a4df9b6f8715a77a7cd79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e129b69eb3f4097a1bee58ea7f70929"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9cd38f146aba47d7b3dc177bd6788a74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"674de677df454f4383a02f64fb9c314a"}},"metadata":{}}]},{"cell_type":"code","source":["#Data\n","import pandas as pd\n","import numpy as np\n","df = pd.read_json(\"/content/syntheticdata.json\")\n","\n","df['evaluation'] = df['evaluation'].apply(lambda x: ', '.join([f\"{key}: {value}\" for key, value in x.items()]))\n","\n","train_texts = df.apply(lambda row: ' '.join(row), axis=1).tolist()\n","\n","# Print the resulting array\n","print(train_texts)"],"metadata":{"id":"qIuN6VG5RWlx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1704675132912,"user_tz":300,"elapsed":214,"user":{"displayName":"Ishaan Salaskar","userId":"15075815353482721876"}},"outputId":"956d6986-fb24-4ce3-c20a-726a3a038bf4"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["['The construction industry is a significant contributor to global waste, producing approximately 1.3 billion tons annually. Utilizing modular and reusable building materials to minimize construction waste. economic_stability: 8, technological_innovation: 7, feasibility: 9, circular_economy: 8 Great solution! Modular construction not only reduces waste but also promotes economic stability and feasibility. Consider exploring even more innovative materials for better technological innovation.', 'The challenge of generating enough electrical power without using fossil fuels is a pressing issue. Investing in solar power farms and advancing energy storage technologies. economic_stability: 9, technological_innovation: 8, feasibility: 7, circular_economy: 6 Your focus on solar power is commendable, showing good economic stability and technological innovation. However, consider exploring circular economy principles for more sustainable solutions.', 'The increased carbon footprint from digital learning platforms and e-waste is a concern. Developing a platform for reusing electronic devices and promoting digital textbooks. economic_stability: 7, technological_innovation: 8, feasibility: 9, circular_economy: 7 Your solution addresses the issue well, with good economic stability and technological innovation. Emphasize circular economy principles further for a more comprehensive approach.', 'The fashion industry is a top contributor to global pollution. Implementing sustainable and recyclable materials in clothing production and encouraging a circular fashion economy. economic_stability: 8, technological_innovation: 6, feasibility: 9, circular_economy: 8 Your emphasis on sustainable materials and circular fashion is commendable. Consider exploring more innovative technologies for better technological innovation.', 'Electronic devices are often replaced before their lifespan ends, leading to significant electronic waste. Designing electronic products with modular components for easy upgrades and repairs. economic_stability: 9, technological_innovation: 8, feasibility: 8, circular_economy: 7 Your approach to modular components is excellent, promoting economic stability and technological innovation. Emphasize circular economy principles for an even more sustainable impact.', 'Businesses worldwide expend substantial resources on paper-based transaction evidence, contributing to environmental degradation. Transitioning to digital receipts and promoting paper recycling initiatives. economic_stability: 7, technological_innovation: 6, feasibility: 8, circular_economy: 7 Digital receipts are a good start, but consider exploring more innovative technologies for better technological innovation. Strengthen circular economy aspects for a more holistic solution.', 'More than 130 billion plastic bottles are wasted annually in Egypt. Implementing a comprehensive plastic recycling program and promoting alternatives like biodegradable packaging. economic_stability: 8, technological_innovation: 7, feasibility: 9, circular_economy: 8 Your focus on recycling and alternative packaging is great. Consider exploring more cutting-edge technologies for better technological innovation.', 'In congested cities like Berlin, finding parking spots for carsharing users is a significant challenge. Developing a smart parking system using IoT technology to optimize parking and handover processes. economic_stability: 9, technological_innovation: 9, feasibility: 8, circular_economy: 6 Your IoT-based solution is impressive, showing good economic stability and technological innovation. Consider integrating more circular economy principles for a more sustainable impact.', 'The surplus of plastic waste is a major global issue, clogging oceans and landfills. Promoting the use of biodegradable plastics and investing in advanced recycling technologies. economic_stability: 8, technological_innovation: 7, feasibility: 8, circular_economy: 9 Your emphasis on biodegradable plastics and advanced recycling technologies is excellent. Strengthen economic stability and technological innovation for an even more impactful solution.', 'The usage of plastic bottles is a widespread environmental concern. Encouraging the use of reusable water bottles and implementing bottle return programs. economic_stability: 7, technological_innovation: 6, feasibility: 8, circular_economy: 9 Your focus on reusable bottles and bottle return programs is commendable. Consider exploring more innovative technologies for better technological innovation.', 'Despite the environmental principles behind a reusable packaging service model, in its current form, it demands significant adjustments from businesses, requires customer cooperation, may induce additional costs, and presents operational risks. A solution to the reusable packaging problem is to implement a user-friendly app that allows customers to easily return and schedule pickups for reusable packaging. The app can provide incentives, such as discounts, to encourage customers to participate in the program. economic_stability: 4, technological_innovation: 6, feasibility: 3, circular_economy: 5 Your solution shows good understanding of the need for customer engagement through technology. However, feasibility and operational risks need more consideration. Also, explore more innovative approaches for better circular economy principles.', \"The fashion industry is the second-largest polluter in the world, right after the oil industry. Every year, the world consumes about 80 billion new pieces of clothing, and this production consumes resources, raises the carbon footprint, and produces waste. The fast fashion cycle encourages this overconsumption model, causing tremendous stress on our planet's resources. Introduce a mandatory carbon tax on fashion items based on their environmental impact. This tax can be used to fund sustainable fashion initiatives and create awareness among consumers about the environmental cost of fast fashion. economic_stability: 7, technological_innovation: 2, feasibility: 5, circular_economy: 8 Your solution addresses economic stability and circular economy principles effectively. However, consider the feasibility of implementing a mandatory carbon tax and explore more innovative technological approaches for awareness.\", \"The fashion industry has a considerable environmental impact due to high resource utilization and waste. However, implementing a 'pure' rental model may face several feasibility and scalability issues, and the environmental benefits may be offset by the footprint of maintenance and logistics. Develop a blockchain-based tracking system for clothing items to ensure efficient maintenance and logistics in a rental model. This technology can enhance transparency, reduce costs, and make the rental model more feasible and scalable. economic_stability: 6, technological_innovation: 9, feasibility: 7, circular_economy: 6 Your solution incorporates advanced technology and addresses feasibility concerns. However, consider potential challenges in implementing blockchain and explore additional circular economy principles.\", 'The solution is meant to solve the issue of electronic waste and reduce the heap of idle electronic products in our homes. Establish community-based e-waste collection centers where residents can drop off their electronic waste. Implement awareness campaigns to educate the community about the importance of proper e-waste disposal and the potential environmental hazards. economic_stability: 5, technological_innovation: 4, feasibility: 6, circular_economy: 7 Your solution addresses community engagement and feasibility aspects. However, consider incorporating more advanced technological solutions for better economic stability and circular economy principles.', 'Single-use plastic packaging has become an all-too-common sight in our environment, resulting in detrimental environmental impacts. Studies show that approximately 8.3 billion tonnes of plastic have been produced since 1950, and 60% of that plastic ends up in either our landfills or the natural environment. Introduce a deposit-refund system for single-use plastic packaging. Consumers pay a deposit for packaging, which they get back when returning the empty packaging. This incentivizes recycling and reduces single-use plastic waste. economic_stability: 8, technological_innovation: 3, feasibility: 7, circular_economy: 9 Your solution is economically sound and supports circular economy principles. However, explore more innovative technological solutions for better feasibility and consider potential challenges in the deposit-refund system implementation.', 'The fashion industry contributes about 10% of global CO2 emissions, with fast fashion being the major contributor. Fast fashion leads to the creation of end-of-life waste, where 85% of textile waste ends up in landfills or is incinerated. Furthermore, the industries involved in the production of fast-fashion are found in developing countries where workers face poor working conditions, and economies struggle due to rising waste management costs. Implement a blockchain-based supply chain management system for the fashion industry. This system can ensure transparency, traceability, and fair labor practices. It can also help in identifying eco-friendly materials and reducing the carbon footprint of fashion products. economic_stability: 7, technological_innovation: 8, feasibility: 6, circular_economy: 7 Your solution integrates advanced technology and addresses economic stability and circular economy principles. However, consider potential challenges in implementing blockchain and explore additional feasibility aspects.', \"Rapid advancement in technology and our demand for the latest electronic devices, such as laptops, computers, and other digital gadgets, result in huge amounts of electronic waste. It's not just harmful for the environment but also poses potential health risks due to the toxic materials contained in these gadgets. Collaborate with tech companies to create modular and upgradable electronic devices. This approach reduces electronic waste as users can upgrade individual components instead of replacing entire devices. Implement educational campaigns to promote the benefits of modular devices. economic_stability: 9, technological_innovation: 10, feasibility: 8, circular_economy: 9 Your solution is innovative, economically sound, and supports circular economy principles. It effectively addresses the environmental and health concerns associated with electronic waste. Well done!\", 'Reducing plastic use in the food industry is a formidable challenge. Conventional mechanisms to incentivize the return of containers are somewhat reliant on individual motivation and may not be effective enough. Develop a smart packaging system embedded with RFID technology. This system automatically tracks and incentivizes the return of food containers. Implement a reward program for consumers who actively participate in recycling, encouraging widespread adoption. economic_stability: 6, technological_innovation: 7, feasibility: 6, circular_economy: 8 Your solution leverages technology effectively and addresses economic stability and circular economy principles. However, explore potential challenges in implementing RFID technology and consider additional ways to enhance feasibility.', \"In a fast-paced, consumer-driven society, electronic waste or e-waste is a growing problem. The average lifespan of electronic gadgets has significantly reduced over the years, culminating in rapid obsolescence and increased generation of e-waste. This problem has grave environmental and health implications as harmful components of e-waste, including mercury, lead, and other toxic elements, can leak into the soil, air, and water. Businesses in the technology sector often adopt a linear model of 'create-consume-dispose,' which accelerates the rate of e-waste generation and masks the potential of valuable resources in such waste for recycling or refurbishment. Implement a system of mandatory e-waste recycling for technology companies, where they must take responsibility for collecting and recycling their products at the end of their life cycle. This will encourage a circular economy and minimize the environmental impact of e-waste. economic_stability: 8, technological_innovation: 7, feasibility: 9, circular_economy: 10 Your solution to implement mandatory e-waste recycling shows a good understanding of the problem. The economic stability, technological innovation, and feasibility aspects are well addressed. The emphasis on a circular economy is commendable, promoting the reuse and recycling of electronic gadgets.\", 'The fast fashion industry promotes high consumption rates, resulting in huge amounts of waste and pollution. There is an unmet need for sustainable fashion consumption that encourages reuse and conservation, adds novelty, and addresses environmental and financial concerns. Introduce a clothing subscription service where customers can rent fashionable clothing items for a specific period. This will reduce the need for constant buying and disposal of clothes, promoting a circular economy in the fashion industry. economic_stability: 7, technological_innovation: 6, feasibility: 8, circular_economy: 9 Your proposal of a clothing subscription service is a creative approach to tackling fast fashion. It addresses economic stability, technological innovation, and feasibility. The focus on a circular economy is noteworthy, emphasizing reuse and conservation in the fashion industry.', \"Encourages a circular economy and minimizes waste by reducing the need for customers to buy new clothes. Launch a campaign promoting the culture of 'slow fashion,' encouraging consumers to invest in high-quality, timeless clothing items that have a longer lifespan. This will reduce the frequency of purchases and contribute to a circular economy. economic_stability: 6, technological_innovation: 5, feasibility: 7, circular_economy: 8 Your idea of promoting 'slow fashion' through a campaign is a positive step towards a circular economy. However, consider incorporating more technological innovation to make the concept more appealing to modern consumers. Enhancing economic stability and feasibility aspects will strengthen the proposal.\", 'Create Awareness of the propensity of Reduce, Reuse, Brick building Develop an educational app that teaches users about the principles of reduce, reuse, and brick building. The app can provide interactive lessons, challenges, and rewards to promote a sustainable lifestyle. economic_stability: 5, technological_innovation: 8, feasibility: 6, circular_economy: 7 Your idea of an educational app is technologically innovative and aligns with the principles of reduce, reuse, and brick building. Consider enhancing economic stability and feasibility aspects, ensuring that the app can reach a wide audience and make a meaningful impact.', 'Encourages a culture of sharing and minimizes waste by reducing the need for customers to buy and dispose of products. Establish a community-driven platform where individuals can share and exchange various products, fostering a culture of sharing and reducing the demand for constant buying. This platform can include items such as electronics, furniture, and clothing. economic_stability: 7, technological_innovation: 6, feasibility: 8, circular_economy: 9 Your proposal for a community-driven sharing platform is a commendable solution. It aligns with the goal of reducing waste and encourages a circular economy. Strengthening technological innovation and addressing economic stability aspects will further enhance the feasibility of the platform.', 'Greenhouse emissions, depleting resources Implement smart building technologies that optimize energy consumption, monitor emissions, and use sustainable materials. Additionally, incentivize businesses to adopt green practices through tax breaks and rewards. economic_stability: 9, technological_innovation: 10, feasibility: 8, circular_economy: 7 Your solution involving smart building technologies is highly innovative and effective in addressing greenhouse emissions and resource depletion. The emphasis on economic stability through tax breaks is a strong point. Consider enhancing the circular economy aspect by incorporating more principles of reuse and recycling in building materials and practices.', 'The extensive energy consumption of buildings due to inefficient equipment and wasteful habits, particularly for lighting and HVAC systems, negatively impacts environmental health and can also be a significant expense for businesses. Introduce an AI-powered energy management system that optimizes lighting and HVAC systems based on occupancy and usage patterns. This will not only reduce energy consumption but also lower costs for businesses. economic_stability: 8, technological_innovation: 9, feasibility: 7, circular_economy: 6 Your proposal for an AI-powered energy management system is technologically advanced and aligns with the goal of reducing energy consumption. Strengthening the circular economy aspect by exploring sustainable building materials and practices will further enhance the feasibility of the solution.', 'Low-density polyethylene (LPDE) material in food packaging and shopping bags Using biodegradable materials for food packaging and shopping bags can be an effective solution. These materials should be eco-friendly and easily recyclable. economic_stability: 7, technological_innovation: 6, feasibility: 8, circular_economy: 9 The proposed solution is promising. It addresses the environmental concerns and aligns well with circular economy principles. However, consider providing more details on the specific biodegradable materials and their sourcing to enhance feasibility.', 'Massive food waste in the restaurant and fast-food industry Implementing a waste reduction program in restaurants by partnering with local charities to donate surplus food can be a good solution. Additionally, promoting the use of biodegradable packaging can further reduce environmental impact. economic_stability: 8, technological_innovation: 5, feasibility: 9, circular_economy: 7 The solution demonstrates a good understanding of the problem. Emphasizing the economic benefits of waste reduction and providing examples of successful partnerships with charities would enhance the proposal.', 'Using human hair to make clothing material Developing a process to convert human hair into textile fibers for clothing can be an innovative solution. This would not only reduce textile waste but also utilize a renewable resource. economic_stability: 6, technological_innovation: 9, feasibility: 7, circular_economy: 8 The proposal showcases technological innovation. To improve, provide more details on the economic viability of this process and potential challenges, ensuring a balanced evaluation of feasibility.', 'Landfills filling up with post-consumer waste from the textile industry Implementing a comprehensive textile recycling program that involves collection, sorting, and recycling of post-consumer textile waste can be an effective solution. Promoting sustainable fashion practices can also reduce demand for new textiles. economic_stability: 8, technological_innovation: 6, feasibility: 9, circular_economy: 8 The proposed solution aligns well with circular economy principles. To enhance the proposal, discuss potential partnerships with recycling facilities and how to incentivize sustainable fashion practices among consumers.', 'E-waste problem from rapid turnover of electronic devices Designing modular electronic devices with easily replaceable parts can extend the lifespan of products. Additionally, implementing a take-back program to collect and recycle old electronic devices would address the e-waste issue. economic_stability: 7, technological_innovation: 8, feasibility: 7, circular_economy: 9 The proposal demonstrates technological innovation. Consider elaborating on how the take-back program would be implemented, including logistics and potential partnerships to improve feasibility.', 'Give companies control over Customer Experience and Reputation Online Implementing a robust online reputation management system that allows companies to monitor and respond to customer reviews can be a solution. This can involve the use of artificial intelligence for sentiment analysis and proactive customer engagement. economic_stability: 9, technological_innovation: 9, feasibility: 8, circular_economy: 3 The proposed solution addresses the online reputation challenge effectively. However, it lacks alignment with circular economy principles. Consider integrating elements of sustainability or resource efficiency in the online reputation management system.']\n"]}]},{"cell_type":"code","source":["tokenized_train_texts = tokenizer(train_texts, truncation=True,\n","                                  padding=True, return_tensors='pt')\n","data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer,\n","                                                mlm=False)"],"metadata":{"id":"v4E21m8zZ_B-","executionInfo":{"status":"ok","timestamp":1704675132917,"user_tz":300,"elapsed":16,"user":{"displayName":"Ishaan Salaskar","userId":"15075815353482721876"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["training_args = TrainingArguments(\n","    output_dir=\"./output\", overwrite_output_dir=True, num_train_epochs=3,\n","    per_device_train_batch_size=16, save_steps=10_000, save_total_limit=2,\n",")\n","\n","trainer = Trainer(\n","    model=model, args=training_args, data_collator=data_collator,\n","    train_dataset=tokenized_train_texts\n",")\n","\n","trainer.train()"],"metadata":{"id":"qX3YP-_yamSq","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"error","timestamp":1704675132918,"user_tz":300,"elapsed":16,"user":{"displayName":"Ishaan Salaskar","userId":"15075815353482721876"}},"outputId":"312efd51-0738-46cd-a420-bd0366e4e189"},"execution_count":6,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"Using the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-759066a77c30>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m training_args = TrainingArguments(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./output\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite_output_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_train_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mper_device_train_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10_000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_total_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memo...\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1440\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m             \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"npu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"xpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36mdevice\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1885\u001b[0m         \"\"\"\n\u001b[1;32m   1886\u001b[0m         \u001b[0mrequires_backends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"torch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1887\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_devices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1889\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, objtype)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mcached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcached\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mcached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m_setup_devices\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1785\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_sagemaker_mp_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_accelerate_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.20.1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1787\u001b[0;31m                 raise ImportError(\n\u001b[0m\u001b[1;32m   1788\u001b[0m                     \u001b[0;34m\"Using the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m                 )\n","\u001b[0;31mImportError\u001b[0m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=tokenized_train_texts\n",")"],"metadata":{"id":"w1sbUCQEa9UH","executionInfo":{"status":"aborted","timestamp":1704675132920,"user_tz":300,"elapsed":16,"user":{"displayName":"Ishaan Salaskar","userId":"15075815353482721876"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"id":"bmEBxbxqa_F8","executionInfo":{"status":"aborted","timestamp":1704675132920,"user_tz":300,"elapsed":15,"user":{"displayName":"Ishaan Salaskar","userId":"15075815353482721876"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","torch.cuda.empty_cache()"],"metadata":{"id":"mgTKgiPOlJO3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import gc\n","del data_collator\n","gc.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O4So37kroaFx","executionInfo":{"status":"ok","timestamp":1704659753359,"user_tz":300,"elapsed":126,"user":{"displayName":"Nishk Patel","userId":"00494709163710383369"}},"outputId":"f01027a1-8f3e-4c95-b6d2-490083c15a05"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["torch.cuda.memory_summary(device=None, abbreviated=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":196},"id":"WsxYtQsMn2uS","executionInfo":{"status":"ok","timestamp":1704659755422,"user_tz":300,"elapsed":155,"user":{"displayName":"Nishk Patel","userId":"00494709163710383369"}},"outputId":"13c06309-ecca-4315-9b43-5eebdbcf8f75"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 4            |        cudaMalloc retries: 4         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |   8320 KiB |  14603 MiB |  52567 MiB |  52559 MiB |\\n|       from large pool |   8320 KiB |  14546 MiB |  52450 MiB |  52442 MiB |\\n|       from small pool |      0 KiB |     57 MiB |    117 MiB |    117 MiB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |   8320 KiB |  14603 MiB |  52567 MiB |  52559 MiB |\\n|       from large pool |   8320 KiB |  14546 MiB |  52450 MiB |  52442 MiB |\\n|       from small pool |      0 KiB |     57 MiB |    117 MiB |    117 MiB |\\n|---------------------------------------------------------------------------|\\n| Requested memory      |   8320 KiB |  14541 MiB |  52252 MiB |  52244 MiB |\\n|       from large pool |   8320 KiB |  14483 MiB |  52135 MiB |  52127 MiB |\\n|       from small pool |      0 KiB |     57 MiB |    117 MiB |    117 MiB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |  14972 MiB |  14972 MiB |  27724 MiB |  12752 MiB |\\n|       from large pool |  14914 MiB |  14914 MiB |  27664 MiB |  12750 MiB |\\n|       from small pool |     58 MiB |     58 MiB |     60 MiB |      2 MiB |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |  32640 KiB | 769260 KiB |  22362 MiB |  22330 MiB |\\n|       from large pool |  32640 KiB | 768144 KiB |  22229 MiB |  22198 MiB |\\n|       from small pool |      0 KiB |  12288 KiB |    132 MiB |    132 MiB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |       1    |     641    |    2078    |    2077    |\\n|       from large pool |       1    |     419    |    1503    |    1502    |\\n|       from small pool |       0    |     223    |     575    |     575    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |       1    |     641    |    2078    |    2077    |\\n|       from large pool |       1    |     419    |    1503    |    1502    |\\n|       from small pool |       0    |     223    |     575    |     575    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |     276    |     277    |     435    |     159    |\\n|       from large pool |     247    |     248    |     405    |     158    |\\n|       from small pool |      29    |      29    |      30    |       1    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       2    |      63    |     801    |     799    |\\n|       from large pool |       2    |      59    |     568    |     566    |\\n|       from small pool |       0    |      39    |     233    |     233    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n","\n","# Load pre-trained model and tokenizer\n","model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"  # Specify the model name from Hugging Face Model Hub\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForSequenceClassification.from_pretrained(model_name)\n","\n","# Assume your dataset is in a CSV file with 'problem', 'solution', and 'score' columns\n","# Create a custom dataset class\n","class CustomDataset(Dataset):\n","    def __init__(self, dataframe):\n","        self.data = dataframe\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        problem_solution = self.data.iloc[idx]['problem'] + ' ' + self.data.iloc[idx]['solution']\n","        score = float(self.data.iloc[idx]['result'])\n","        return problem_solution, score\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_BpYXQfmn5Hy","executionInfo":{"status":"ok","timestamp":1704661419021,"user_tz":300,"elapsed":20010,"user":{"displayName":"Nishk Patel","userId":"00494709163710383369"}},"outputId":"5f9da836-a2e1-47fb-84fa-00216b7038bd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at TinyLlama/TinyLlama-1.1B-Chat-v1.0 and are newly initialized: ['score.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["\n","# Load and split your dataset (assuming you have a pandas DataFrame)\n","# train_data, val_data, test_data = split_your_dataset_accordingly()\n","df = pd.read_json(\"/content/syntheticdata.json\")\n","# df[\"input\"] = \"Problem: \" + df[\"problem\"] + \" Solution: \" + [\"solution\"]\n","df['evaluation'] = df['evaluation'].apply(lambda x: ', '.join([f\"{key}: {value}\" for key, value in x.items()]))\n","df[\"result\"] = df[\"evaluation\"] + df[\"feedback\"]\n","\n","df = df.drop(['feedback', 'evaluation'], axis =1)\n","df"],"metadata":{"id":"F5UzGrmAuIgc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_texts = df.fillna(0)\n","# Create DataLoader for training\n","train_texts\n","train_loader = DataLoader(train_texts, batch_size=8, shuffle=True)\n","\n","# Training settings\n","num_epochs = 1\n","learning_rate = 2e-5\n","optimizer = AdamW(model.parameters(), lr=learning_rate)\n","print(train_texts)\n","# Training loop\n","for epoch in range(num_epochs):\n","    model.train()\n","    for batch in train_loader:\n","        inputs, labels = batch\n","        inputs = tokenizer(inputs, return_tensors=\"pt\", padding=True, truncation=True)\n","        labels = torch.tensor(labels).unsqueeze(1)\n","\n","        # Forward pass\n","        outputs = model(**inputs)\n","        loss = torch.nn.functional.mse_loss(outputs.logits, labels)\n","\n","        # Backward pass and optimization\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"glQPNMNFuFUH","executionInfo":{"status":"error","timestamp":1704661257566,"user_tz":300,"elapsed":166,"user":{"displayName":"Nishk Patel","userId":"00494709163710383369"}},"outputId":"f23e6299-6027-42b1-a099-4618757d6cfa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                input  \\\n","0   Problem: The construction industry is a signif...   \n","1   Problem: The challenge of generating enough el...   \n","2   Problem: The increased carbon footprint from d...   \n","3   Problem: The fashion industry is a top contrib...   \n","4   Problem: Electronic devices are often replaced...   \n","5   Problem: Businesses worldwide expend substanti...   \n","6   Problem: More than 130 billion plastic bottles...   \n","7   Problem: In congested cities like Berlin, find...   \n","8   Problem: The surplus of plastic waste is a maj...   \n","9   Problem: The usage of plastic bottles is a wid...   \n","10  Problem: Despite the environmental principles ...   \n","11  Problem: The fashion industry is the second-la...   \n","12  Problem: The fashion industry has a considerab...   \n","13  Problem: The solution is meant to solve the is...   \n","14  Problem: Single-use plastic packaging has beco...   \n","15  Problem: The fashion industry contributes abou...   \n","16  Problem: Rapid advancement in technology and o...   \n","17  Problem: Reducing plastic use in the food indu...   \n","18  Problem: In a fast-paced, consumer-driven soci...   \n","19  Problem: The fast fashion industry promotes hi...   \n","20  Problem: Encourages a circular economy and min...   \n","21  Problem: Create Awareness of the propensity of...   \n","22  Problem: Encourages a culture of sharing and m...   \n","23  Problem: Greenhouse emissions, depleting resou...   \n","24  Problem: The extensive energy consumption of b...   \n","25  Problem: Low-density polyethylene (LPDE) mater...   \n","26  Problem: Massive food waste in the restaurant ...   \n","27  Problem: Using human hair to make clothing mat...   \n","28  Problem: Landfills filling up with post-consum...   \n","29  Problem: E-waste problem from rapid turnover o...   \n","30  Problem: Give companies control over Customer ...   \n","\n","                                               result  \n","0   economic_stability: 8, technological_innovatio...  \n","1   economic_stability: 9, technological_innovatio...  \n","2   economic_stability: 7, technological_innovatio...  \n","3   economic_stability: 8, technological_innovatio...  \n","4   economic_stability: 9, technological_innovatio...  \n","5   economic_stability: 7, technological_innovatio...  \n","6   economic_stability: 8, technological_innovatio...  \n","7   economic_stability: 9, technological_innovatio...  \n","8   economic_stability: 8, technological_innovatio...  \n","9   economic_stability: 7, technological_innovatio...  \n","10  economic_stability: 4, technological_innovatio...  \n","11  economic_stability: 7, technological_innovatio...  \n","12  economic_stability: 6, technological_innovatio...  \n","13  economic_stability: 5, technological_innovatio...  \n","14  economic_stability: 8, technological_innovatio...  \n","15  economic_stability: 7, technological_innovatio...  \n","16  economic_stability: 9, technological_innovatio...  \n","17  economic_stability: 6, technological_innovatio...  \n","18  economic_stability: 8, technological_innovatio...  \n","19  economic_stability: 7, technological_innovatio...  \n","20  economic_stability: 6, technological_innovatio...  \n","21  economic_stability: 5, technological_innovatio...  \n","22  economic_stability: 7, technological_innovatio...  \n","23  economic_stability: 9, technological_innovatio...  \n","24  economic_stability: 8, technological_innovatio...  \n","25  economic_stability: 7, technological_innovatio...  \n","26  economic_stability: 8, technological_innovatio...  \n","27  economic_stability: 6, technological_innovatio...  \n","28  economic_stability: 8, technological_innovatio...  \n","29  economic_stability: 7, technological_innovatio...  \n","30  economic_stability: 9, technological_innovatio...  \n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"error","ename":"KeyError","evalue":"5","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 5","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-80-0ee5698ecaab>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 5"]}]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"DQo7bQDhsqCu","executionInfo":{"status":"ok","timestamp":1704660958538,"user_tz":300,"elapsed":144,"user":{"displayName":"Nishk Patel","userId":"00494709163710383369"}},"outputId":"d764f8c6-e12a-44f5-dda6-56a22529ec25"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                input  \\\n","0   Problem: The construction industry is a signif...   \n","1   Problem: The challenge of generating enough el...   \n","2   Problem: The increased carbon footprint from d...   \n","3   Problem: The fashion industry is a top contrib...   \n","4   Problem: Electronic devices are often replaced...   \n","5   Problem: Businesses worldwide expend substanti...   \n","6   Problem: More than 130 billion plastic bottles...   \n","7   Problem: In congested cities like Berlin, find...   \n","8   Problem: The surplus of plastic waste is a maj...   \n","9   Problem: The usage of plastic bottles is a wid...   \n","10  Problem: Despite the environmental principles ...   \n","11  Problem: The fashion industry is the second-la...   \n","12  Problem: The fashion industry has a considerab...   \n","13  Problem: The solution is meant to solve the is...   \n","14  Problem: Single-use plastic packaging has beco...   \n","15  Problem: The fashion industry contributes abou...   \n","16  Problem: Rapid advancement in technology and o...   \n","17  Problem: Reducing plastic use in the food indu...   \n","18  Problem: In a fast-paced, consumer-driven soci...   \n","19  Problem: The fast fashion industry promotes hi...   \n","20  Problem: Encourages a circular economy and min...   \n","21  Problem: Create Awareness of the propensity of...   \n","22  Problem: Encourages a culture of sharing and m...   \n","23  Problem: Greenhouse emissions, depleting resou...   \n","24  Problem: The extensive energy consumption of b...   \n","25  Problem: Low-density polyethylene (LPDE) mater...   \n","26  Problem: Massive food waste in the restaurant ...   \n","27  Problem: Using human hair to make clothing mat...   \n","28  Problem: Landfills filling up with post-consum...   \n","29  Problem: E-waste problem from rapid turnover o...   \n","30  Problem: Give companies control over Customer ...   \n","\n","                                               result  \n","0   economic_stability: 8, technological_innovatio...  \n","1   economic_stability: 9, technological_innovatio...  \n","2   economic_stability: 7, technological_innovatio...  \n","3   economic_stability: 8, technological_innovatio...  \n","4   economic_stability: 9, technological_innovatio...  \n","5   economic_stability: 7, technological_innovatio...  \n","6   economic_stability: 8, technological_innovatio...  \n","7   economic_stability: 9, technological_innovatio...  \n","8   economic_stability: 8, technological_innovatio...  \n","9   economic_stability: 7, technological_innovatio...  \n","10  economic_stability: 4, technological_innovatio...  \n","11  economic_stability: 7, technological_innovatio...  \n","12  economic_stability: 6, technological_innovatio...  \n","13  economic_stability: 5, technological_innovatio...  \n","14  economic_stability: 8, technological_innovatio...  \n","15  economic_stability: 7, technological_innovatio...  \n","16  economic_stability: 9, technological_innovatio...  \n","17  economic_stability: 6, technological_innovatio...  \n","18  economic_stability: 8, technological_innovatio...  \n","19  economic_stability: 7, technological_innovatio...  \n","20  economic_stability: 6, technological_innovatio...  \n","21  economic_stability: 5, technological_innovatio...  \n","22  economic_stability: 7, technological_innovatio...  \n","23  economic_stability: 9, technological_innovatio...  \n","24  economic_stability: 8, technological_innovatio...  \n","25  economic_stability: 7, technological_innovatio...  \n","26  economic_stability: 8, technological_innovatio...  \n","27  economic_stability: 6, technological_innovatio...  \n","28  economic_stability: 8, technological_innovatio...  \n","29  economic_stability: 7, technological_innovatio...  \n","30  economic_stability: 9, technological_innovatio...  "],"text/html":["\n","  <div id=\"df-61f4b4d1-c751-4d14-96d5-f69104c20019\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>input</th>\n","      <th>result</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Problem: The construction industry is a signif...</td>\n","      <td>economic_stability: 8, technological_innovatio...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Problem: The challenge of generating enough el...</td>\n","      <td>economic_stability: 9, technological_innovatio...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Problem: The increased carbon footprint from d...</td>\n","      <td>economic_stability: 7, technological_innovatio...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Problem: The fashion industry is a top contrib...</td>\n","      <td>economic_stability: 8, technological_innovatio...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Problem: Electronic devices are often replaced...</td>\n","      <td>economic_stability: 9, technological_innovatio...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Problem: Businesses worldwide expend substanti...</td>\n","      <td>economic_stability: 7, technological_innovatio...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Problem: More than 130 billion plastic bottles...</td>\n","      <td>economic_stability: 8, technological_innovatio...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Problem: In congested cities like Berlin, find...</td>\n","      <td>economic_stability: 9, technological_innovatio...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Problem: The surplus of plastic waste is a maj...</td>\n","      <td>economic_stability: 8, technological_innovatio...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Problem: The usage of plastic bottles is a wid...</td>\n","      <td>economic_stability: 7, technological_innovatio...</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Problem: Despite the environmental principles ...</td>\n","      <td>economic_stability: 4, technological_innovatio...</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>Problem: The fashion industry is the second-la...</td>\n","      <td>economic_stability: 7, technological_innovatio...</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>Problem: The fashion industry has a considerab...</td>\n","      <td>economic_stability: 6, technological_innovatio...</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>Problem: The solution is meant to solve the is...</td>\n","      <td>economic_stability: 5, technological_innovatio...</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>Problem: Single-use plastic packaging has beco...</td>\n","      <td>economic_stability: 8, technological_innovatio...</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>Problem: The fashion industry contributes abou...</td>\n","      <td>economic_stability: 7, technological_innovatio...</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>Problem: Rapid advancement in technology and o...</td>\n","      <td>economic_stability: 9, technological_innovatio...</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>Problem: Reducing plastic use in the food indu...</td>\n","      <td>economic_stability: 6, technological_innovatio...</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>Problem: In a fast-paced, consumer-driven soci...</td>\n","      <td>economic_stability: 8, technological_innovatio...</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>Problem: The fast fashion industry promotes hi...</td>\n","      <td>economic_stability: 7, technological_innovatio...</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>Problem: Encourages a circular economy and min...</td>\n","      <td>economic_stability: 6, technological_innovatio...</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>Problem: Create Awareness of the propensity of...</td>\n","      <td>economic_stability: 5, technological_innovatio...</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>Problem: Encourages a culture of sharing and m...</td>\n","      <td>economic_stability: 7, technological_innovatio...</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>Problem: Greenhouse emissions, depleting resou...</td>\n","      <td>economic_stability: 9, technological_innovatio...</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>Problem: The extensive energy consumption of b...</td>\n","      <td>economic_stability: 8, technological_innovatio...</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>Problem: Low-density polyethylene (LPDE) mater...</td>\n","      <td>economic_stability: 7, technological_innovatio...</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>Problem: Massive food waste in the restaurant ...</td>\n","      <td>economic_stability: 8, technological_innovatio...</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>Problem: Using human hair to make clothing mat...</td>\n","      <td>economic_stability: 6, technological_innovatio...</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>Problem: Landfills filling up with post-consum...</td>\n","      <td>economic_stability: 8, technological_innovatio...</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>Problem: E-waste problem from rapid turnover o...</td>\n","      <td>economic_stability: 7, technological_innovatio...</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>Problem: Give companies control over Customer ...</td>\n","      <td>economic_stability: 9, technological_innovatio...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61f4b4d1-c751-4d14-96d5-f69104c20019')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-61f4b4d1-c751-4d14-96d5-f69104c20019 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-61f4b4d1-c751-4d14-96d5-f69104c20019');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-2b42af87-1944-497a-8ab1-2d014a6367af\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2b42af87-1944-497a-8ab1-2d014a6367af')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-2b42af87-1944-497a-8ab1-2d014a6367af button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":63}]},{"cell_type":"code","source":[],"metadata":{"id":"A6O_BGyqsLtK"},"execution_count":null,"outputs":[]}]}